{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping with Python Selenium\n",
    "**By Jayden Nyamiaka**\n",
    "\n",
    "In this notebook, we will get started with web scraping using Python's Selenium drivers. Selenium tends to be more robust and flexible than Beautiful Soup. For this exercise, we will scrape Wikipedia and Tineye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup ChromeDriver\n",
    "service = Service()\n",
    "options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(service=service, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAVIGATE TO WIKIPEDIA AND SEARCH FOR CALTECH\n",
    "\n",
    "# Navigate to Wikipedia\n",
    "wikipedia_url = \"https://en.wikipedia.org/wiki/Main_Page\"\n",
    "driver.get(wikipedia_url)\n",
    "\n",
    "# Toggle the search bar to be visible if it isn't already\n",
    "try: \n",
    "    search_toggle = driver.find_element(By.CLASS_NAME, \"search-toggle\")\n",
    "    search_toggle.click()\n",
    "except: \n",
    "    pass\n",
    "\n",
    "# Get the search bar element (accounting for the refresh)\n",
    "# Wait until the element is stale and then visible again\n",
    "search_bar = driver.find_element(By.NAME, \"search\")\n",
    "try:\n",
    "    WebDriverWait(driver, 10).until(EC.staleness_of(search_bar))\n",
    "    search_bar = WebDriverWait(driver, 10).until(EC.visibility_of_element_located(\n",
    "        (By.NAME, \"search\")))\n",
    "except:\n",
    "    search_bar = driver.find_element(By.NAME, \"search\")\n",
    "\n",
    "# Search Caltech in the search bar\n",
    "search_bar.send_keys(\"Caltech\")\n",
    "\n",
    "# Click the search button\n",
    "search_button = driver.find_element(By.CLASS_NAME, \"cdx-search-input__end-button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>years</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1915</td>\n",
       "      <td>The Southern California Intercollegiate Athlet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1920</td>\n",
       "      <td>The Southern Branch of the University of Calif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1926</td>\n",
       "      <td>La Verne College (now the University of La Ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1927</td>\n",
       "      <td>UCLA left the SCIAC, effective after the 1926-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1931</td>\n",
       "      <td>Santa Barbara State College (now the Universit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1934</td>\n",
       "      <td>Caltech and Pomona left the SCIAC, effective a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1938</td>\n",
       "      <td>La Verne and UC Santa Barbara left the SCIAC, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1938</td>\n",
       "      <td>Caltech and Pomona re-joined the SCIAC, effect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1939</td>\n",
       "      <td>San Diego State left the SCIAC, effective afte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1943</td>\n",
       "      <td>Whittier left the SCIAC, effective after the 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1946</td>\n",
       "      <td>Whittier re-joined the SCIAC, effective in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1947</td>\n",
       "      <td>Claremont Men's College (now Claremont McKenna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1950</td>\n",
       "      <td>Chapman College (now Chapman University) joine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1952</td>\n",
       "      <td>Chapman left the SCIAC, effective after the 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1958</td>\n",
       "      <td>Claremont combined with Harvey Mudd College fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1971</td>\n",
       "      <td>Pomona combined with Pitzer College for athlet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1976</td>\n",
       "      <td>Claremont–Mudd combined with Scripps College f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1991</td>\n",
       "      <td>California Lutheran University joined the SCIA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2011</td>\n",
       "      <td>Chapman re-joined back to the SCIAC, effective...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020</td>\n",
       "      <td>Occidental dropped its football program before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023</td>\n",
       "      <td>Whittier dropped its football program after th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   years                                        description\n",
       "0   1915  The Southern California Intercollegiate Athlet...\n",
       "1   1920  The Southern Branch of the University of Calif...\n",
       "2   1926  La Verne College (now the University of La Ver...\n",
       "3   1927  UCLA left the SCIAC, effective after the 1926-...\n",
       "4   1931  Santa Barbara State College (now the Universit...\n",
       "5   1934  Caltech and Pomona left the SCIAC, effective a...\n",
       "6   1938  La Verne and UC Santa Barbara left the SCIAC, ...\n",
       "7   1938  Caltech and Pomona re-joined the SCIAC, effect...\n",
       "8   1939  San Diego State left the SCIAC, effective afte...\n",
       "9   1943  Whittier left the SCIAC, effective after the 1...\n",
       "10  1946  Whittier re-joined the SCIAC, effective in the...\n",
       "11  1947  Claremont Men's College (now Claremont McKenna...\n",
       "12  1950  Chapman College (now Chapman University) joine...\n",
       "13  1952  Chapman left the SCIAC, effective after the 19...\n",
       "14  1958  Claremont combined with Harvey Mudd College fo...\n",
       "15  1971  Pomona combined with Pitzer College for athlet...\n",
       "16  1976  Claremont–Mudd combined with Scripps College f...\n",
       "17  1991  California Lutheran University joined the SCIA...\n",
       "18  2011  Chapman re-joined back to the SCIAC, effective...\n",
       "19  2020  Occidental dropped its football program before...\n",
       "20  2023  Whittier dropped its football program after th..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NAVIGATE TO SCIAC PAGE AND SCRAPE CHRONOLOGICAL TIMELINE\n",
    "\n",
    "# Find and click on the SCIAC sporting affliations link\n",
    "sciac_link = driver.find_element(By.PARTIAL_LINK_TEXT, \"Southern California Intercollegiate Athletic Conference\")\n",
    "sciac_link.click()\n",
    "\n",
    "# Scrape the Chronological Timeline and make a df with the year and description of every element\n",
    "timeline_list = driver.find_element(By.XPATH, \"/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/ul[1]\")\n",
    "timeline_elems = timeline_list.find_elements(By.TAG_NAME, 'li')\n",
    "\n",
    "years = []\n",
    "descriptions = []\n",
    "\n",
    "for elem in timeline_elems:\n",
    "    text = elem.text\n",
    "    years.append(text[:4])\n",
    "    descriptions.append(text[7:])\n",
    "\n",
    "df_timeline = pd.DataFrame({\"years\": years, \"description\": descriptions})\n",
    "display(df_timeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of websites: 110\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website</th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>www.alamy.com</td>\n",
       "      <td>https://www.alamy.com/stock-image-tolman-26-ei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www.yoka.com</td>\n",
       "      <td>http://www.yoka.com/dna/li/c172.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fa.wikipedia.org</td>\n",
       "      <td>https://fa.wikipedia.org/wiki/%D8%B1%DB%8C%DA%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>www.yoka.com</td>\n",
       "      <td>http://www.yoka.com/dna/m/t54262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wemedia.ifeng.com</td>\n",
       "      <td>http://wemedia.ifeng.com/8815421/wemedia.shtml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>wildup.la</td>\n",
       "      <td>http://wildup.la/events/past-events/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>blogs.mediapart.fr</td>\n",
       "      <td>https://blogs.mediapart.fr/edition/la-mendie-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>defenceforumindia.com</td>\n",
       "      <td>https://defenceforumindia.com/threads/indian-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>linkiesta.it</td>\n",
       "      <td>http://linkiesta.it/cultura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>defenceforumindia.com</td>\n",
       "      <td>https://defenceforumindia.com/threads/indian-s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   website                                               urls\n",
       "0            www.alamy.com  https://www.alamy.com/stock-image-tolman-26-ei...\n",
       "1             www.yoka.com               http://www.yoka.com/dna/li/c172.html\n",
       "2         fa.wikipedia.org  https://fa.wikipedia.org/wiki/%D8%B1%DB%8C%DA%...\n",
       "3             www.yoka.com                   http://www.yoka.com/dna/m/t54262\n",
       "4        wemedia.ifeng.com     http://wemedia.ifeng.com/8815421/wemedia.shtml\n",
       "..                     ...                                                ...\n",
       "105              wildup.la               http://wildup.la/events/past-events/\n",
       "106     blogs.mediapart.fr  https://blogs.mediapart.fr/edition/la-mendie-b...\n",
       "107  defenceforumindia.com  https://defenceforumindia.com/threads/indian-s...\n",
       "108           linkiesta.it                        http://linkiesta.it/cultura\n",
       "109  defenceforumindia.com  https://defenceforumindia.com/threads/indian-s...\n",
       "\n",
       "[110 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GO BACK TO CALTECH PAGE, SAVE AND REVERSE SEARCH IMAGE OF TOLMAN AND EINSTEIN, \n",
    "# AND SCRAPE THE RESULTS\n",
    "\n",
    "# Go back to Caltech Wikipedia page\n",
    "driver.back()\n",
    "\n",
    "# Find and download the image of Tolman and Einstein at Caltech\n",
    "img = WebDriverWait(driver, 10).until(EC.visibility_of_element_located(\n",
    "    (By.XPATH, '//*[@id=\"mw-content-text\"]/div[1]/figure[5]/a/img')))\n",
    "img_url = img.get_attribute(\"src\")\n",
    "\n",
    "img_resp = requests.get(img_url)\n",
    "img_filename = \"Richard C. Tolman and Albert Einstein at Caltech, 1932.jpg\"\n",
    "with open(img_filename, \"wb\") as f:\n",
    "    f.write(img_resp.content)\n",
    "\n",
    "# Navigate to Tineye (for reverse image searching)\n",
    "tineye_url = \"https://tineye.com/\"\n",
    "driver.get(tineye_url)\n",
    "\n",
    "# Search for the image url in the search box and click the submit button\n",
    "url_box = WebDriverWait(driver, 10).until(EC.visibility_of_element_located(\n",
    "    (By.ID, \"url_box\")))\n",
    "url_box.send_keys(img_url)\n",
    "submit_button = driver.find_element(By.ID, \"url_submit\")\n",
    "submit_button.click()\n",
    "\n",
    "# Scrape the results and put them into a dataframe\n",
    "websites = []\n",
    "urls = []\n",
    " \n",
    "# Loop through all pages of results\n",
    "are_more_results = True\n",
    "while (are_more_results):\n",
    "    # Wait until results have loaded in\n",
    "    results = WebDriverWait(driver, 10).until(EC.visibility_of_element_located(\n",
    "        (By.CLASS_NAME, \"results\")\n",
    "    ))\n",
    "    # Extract the website and links from each result block\n",
    "    result_elems = results.find_elements(By.CLASS_NAME, \"match\")\n",
    "    for result_elem in result_elems:\n",
    "        website = result_elem.find_element(By.TAG_NAME, \"h4\").text\n",
    "        data_elem = result_elem.find_element(By.TAG_NAME, \"p\")\n",
    "        \n",
    "        links = []\n",
    "        link_elems = data_elem.find_elements(By.TAG_NAME, \"a\")\n",
    "        for link_elem in link_elems:\n",
    "            link = link_elem.get_attribute(\"href\")\n",
    "            links.append(link)\n",
    "\n",
    "        websites.append(website)\n",
    "        urls.append(\", \".join(links)) # Concatenate all links as comma-separated string\n",
    "    \n",
    "    # Click the next page button if not on the last page\n",
    "    row_div = driver.find_element(By.CLASS_NAME, \"sorting-row\")\n",
    "    if (row_div.get_attribute(\"currentpage\") == row_div.get_attribute(\"totalpages\")):\n",
    "        break\n",
    "    else:\n",
    "        next_button = driver.find_element(By.CLASS_NAME, \"next\")\n",
    "        next_button.click()\n",
    "\n",
    "df_websites = pd.DataFrame({\"website\": websites, \"urls\": urls})\n",
    "print(\"Number of websites: \" + str(len(websites)))\n",
    "display(df_websites)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
